<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0037)http://www.ping.be/~ping1339/matr.htm -->
<HTML><HEAD><TITLE>An introduction to MATRICES</TITLE>
<META http-equiv=Content-Type content="text/html; charset=windows-1252">
<META content="MSHTML 5.50.4134.600" name=GENERATOR></HEAD>
<BODY bgColor=#f0f0f0>
<H1>An introduction to MATRICES </H1>
<HR>

<UL>
  <UL>
    <LI><A href="http://www.ping.be/~ping1339/matr.htm#Definitions">Definitions 
    </A><BR>
    <UL>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Matrix">Matrix </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Square-matrix">Square 
      matrix </A><BR>
      <LI><A 
      href="http://www.ping.be/~ping1339/matr.htm#Diagonal-matrix">Diagonal 
      matrix </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Row-matrix">Row matrix 
      </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Column-matrix">Column 
      matrix </A><BR>
      <LI><A 
      href="http://www.ping.be/~ping1339/matr.htm#Matrices-of-the-same">Matrices 
      of the same kind </A><BR>
      <LI><A 
      href="http://www.ping.be/~ping1339/matr.htm#The-tranpose-of-a-ma">The 
      tranpose of a matrix </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#0-matrix">0-matrix 
      </A><BR>
      <LI><A 
      href="http://www.ping.be/~ping1339/matr.htm#An-identity-matrix-I">An 
      identity matrix I </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#A-scalar-matrix-S">A 
      scalar matrix S </A><BR>
      <LI><A 
      href="http://www.ping.be/~ping1339/matr.htm#The-opposite-matrix-">The 
      opposite matrix of a matrix </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#A-symmetric-matrix">A 
      symmetric matrix </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#A-skew-symmetric-mat">A 
      skew-symmetric matrix </A><BR></LI></UL>
    <LI><A href="http://www.ping.be/~ping1339/matr.htm#The-sum-of-matrices-">The 
    sum of matrices of the same kind </A><BR>
    <UL>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Sum-of-matrices">Sum of 
      matrices </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Sum-properties">Sum 
      properties </A><BR></LI></UL>
    <LI><A 
    href="http://www.ping.be/~ping1339/matr.htm#Scalar-multiplicatio">Scalar 
    multiplication </A><BR>
    <UL>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Definition">Definition 
      </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Properties">Properties 
      </A><BR></LI></UL>
    <LI><A href="http://www.ping.be/~ping1339/matr.htm#Sums-in-math">Sums in 
    math </A><BR>
    <LI><A 
    href="http://www.ping.be/~ping1339/matr.htm#Multiplication-of-a-">Multiplication 
    of a row matrix by a column matrix </A><BR>
    <LI><A 
    href="http://www.ping.be/~ping1339/matr.htm#Multiplication-of-tw">Multiplication 
    of two matrices A.B </A><BR>
    <LI><A 
    href="http://www.ping.be/~ping1339/matr.htm#Properties-of-multip">Properties 
    of multiplication of matrices </A><BR>
    <UL>
      <LI><A 
      href="http://www.ping.be/~ping1339/matr.htm#Associativity">Associativity 
      </A><BR>
      <LI><A 
      href="http://www.ping.be/~ping1339/matr.htm#Distributivity">Distributivity 
      </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Theorem-1">Theorem 1 
      </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Theorem-2">Theorem 2 
      </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Theorem-3">Theorem 3 
      </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Theorem-4">Theorem 4 
      </A><BR>
      <LI><A href="http://www.ping.be/~ping1339/matr.htm#Theorem-5">Theorem 5 
      </A><BR></LI></UL></LI></UL></UL>
<HR>

<H3><A name=Definitions><FONT color=#cc6600>Definitions</FONT></A></H3>
<H4><A name=Matrix><FONT color=#008c05>Matrix</FONT></A></H4>
<P>A matrix is an ordered set of numbers listed rectangular form. 
<P>Example. Let A denote the matrix <PRE> 
        [2  5  7  8]
        [5  6  8  9]
        [3  9  0  1]
</PRE>
<P>This matrix A has three rows and four columns. We say it is a 3 x 4 matrix. 
<P>We denote the element on the second row and fourth column with 
a<SUB>2,4</SUB>. 
<H4><A name=Square-matrix><FONT color=#008c05>Square matrix</FONT></A></H4>
<P>If a matrix A has n rows and n columns then we say it's a square matrix. 
<P>In a square matrix the elements a<SUB>i,i</SUB> , with i = 1,2,3,... , are 
called diagonal elements.<BR>Remark. There is no difference between a 1 x 1 
matrix and an ordenary number. 
<H4><A name=Diagonal-matrix><FONT color=#008c05>Diagonal matrix</FONT></A></H4>A 
diagonal matrix is a square matrix with all de non-diagonal elements 0.<BR>The 
diagonal matrix is completely denoted by the diagonal elements.<BR>Example. <PRE> 
        [7  0  0]
        [0  5  0]
        [0  0  6]

The matrix is denoted by diag(7 , 5 , 6)
</PRE>
<H4><A name=Row-matrix><FONT color=#008c05>Row matrix</FONT></A></H4>A matrix 
with one row is called a row matrix 
<H4><A name=Column-matrix><FONT color=#008c05>Column matrix</FONT></A></H4>A 
matrix with one column is called a column matrix 
<H4><A name=Matrices-of-the-same><FONT color=#008c05>Matrices of the same 
kind</FONT></A></H4>
<P>Matrix A and B are of the same kind if and only if <BR>A has as many rows as 
B and A has as many columns as B 
<H4><A name=The-tranpose-of-a-ma><FONT color=#008c05>The tranpose of a 
matrix</FONT></A></H4>
<P>The n x m matrix A' is the transpose of the m x n matrix A if and only if 
<BR>The ith row of A = the ith column of A' for (i = 1,2,3,..n)<BR>So 
a<SUB>i,j</SUB> = a<SUB>j,i</SUB>' <PRE> 
The transpose of A is denoted T(A) or A<SUP>T</SUP>
</PRE>
<H4><A name=0-matrix><FONT color=#008c05>0-matrix</FONT></A></H4>
<P>When all the elements of a matrix A are 0, we call A a 0-matrix.<BR>We write 
shortly 0 for a 0-matrix. 
<H4><A name=An-identity-matrix-I><FONT color=#008c05>An identity matrix 
I</FONT></A></H4>
<P>An identity matrix I is a diagonal matrix with all diagonal element = 1. 
<H4><A name=A-scalar-matrix-S><FONT color=#008c05>A scalar matrix 
S</FONT></A></H4>
<P>A scalar matrix S is a diagonal matrix with all diagonal elements 
alike.<BR>a<SUB>1,1</SUB> = a<SUB>i,i</SUB> for (i = 1,2,3,..n) 
<H4><A name=The-opposite-matrix-><FONT color=#008c05>The opposite matrix of a 
matrix</FONT></A></H4>If we change the sign of all the elements of a matrix A, 
we have the opposite matrix -A.<BR>If A' is the opposite of A then 
a<SUB>i,j</SUB>' = -a<SUB>i,j</SUB>, for all i and j. 
<H4><A name=A-symmetric-matrix><FONT color=#008c05>A symmetric 
matrix</FONT></A></H4>
<P>A square matrix is called symmetric if it is equal to its transpose.<BR>Then 
a<SUB>i,j</SUB> = a<SUB>j,i</SUB> , for all i and j. 
<H4><A name=A-skew-symmetric-mat><FONT color=#008c05>A skew-symmetric 
matrix</FONT></A></H4>
<P>A square matrix is called skew-symmetric if it is equal to the opposite of 
its transpose.<BR>Then a<SUB>i,j</SUB> = -a<SUB>j,i</SUB> , for all i and j. 
<H3><A name=The-sum-of-matrices-><FONT color=#cc6600>The sum of matrices of the 
same kind</FONT></A></H3>
<H4><A name=Sum-of-matrices><FONT color=#008c05>Sum of matrices</FONT></A></H4>
<P>To add two matrices of the same kind, we simply add the corresponding 
elements. 
<H4><A name=Sum-properties><FONT color=#008c05>Sum properties</FONT></A></H4>
<P>Consider the set S of all n x m matrices (n and m fixed) and A and B are in 
S.<BR>From the properties of real numbers it's immediate that 
<UL>
  <LI>A + B is in S 
  <LI>the addition of matrices is associative in S 
  <LI>A + 0 = A = 0 + A 
  <LI>with each A corresponds an opposite matrix -A 
  <LI>A + B = B + A </LI></UL>
<H3><A name=Scalar-multiplicatio><FONT color=#cc6600>Scalar 
multiplication</FONT></A></H3>
<H4><A name=Definition><FONT color=#008c05>Definition</FONT></A></H4>
<P>To multiply a matrix with a real number, we multiply each element with this 
number. 
<H4><A name=Properties><FONT color=#008c05>Properties</FONT></A></H4>
<P>Consider the set S of all n x m matrices (n and m fixed). A and B are in S; r 
and s are real numbers. <BR>It is not difficult to see that: <PRE> 
    r(A+B) = rA+rB
    (r+s)A = rA+sA
    (rs)A = r(sA)
    (A + B)<SUP>T</SUP>  = A<SUP>T</SUP>  + B<SUP>T</SUP>
    (rA)<SUP>T</SUP> = r. A<SUP>T</SUP>

</PRE>
<H3><A name=Sums-in-math><FONT color=#cc6600>Sums in math</FONT></A></H3>Because 
in the following, there is an intensive use of the properties of sums, the 
reader who is not familiar with these properties must read first <A 
href="http://www.ping.be/~ping1339/sigma.htm">Sums in math </A>.<BR>Remark. In 
this html document, for convenience, we'll write the word sum instead of the 
sigma sign.<BR>
<H3><A name=Multiplication-of-a-><FONT color=#cc6600>Multiplication of a row 
matrix by a column matrix</FONT></A></H3>
<P>This multiplication is only possible if the row matrix and the column matrix 
have the same number of elements. The result is a ordinary number ( 1 x 1 
matrix).<BR>To multiply the row by the column, one multiplies corresponding 
elements, then adds the results.<BR>Example. <PRE> 
         [1]
[2 1 3]. [2] = [19]
         [5]
</PRE>
<H3><A name=Multiplication-of-tw><FONT color=#cc6600>Multiplication of two 
matrices A.B</FONT></A></H3>This product is defined only if A is a (l x m) 
matrix and B is a (m x n) matrix.<BR>So the number of columns of A has to be 
equal to the number of rows of B.<BR>The product C = A.B then is a (l x n) 
matrix.<BR>The element of the ith row and the jth column of the product is found 
by multiplying the ith row of A by the jth column of B. <PRE> 
        c<SUB>i,j</SUB> = sum<SUB>k</SUB> (a<SUB>i,k</SUB>.b<SUB>k,j</SUB>)
</PRE>Example. <PRE> 
[1 2][1 3] = [5 7]
[2 1][2 2]   [4 8]

[1 3][1 2] = [7 5]
[2 2][2 1]   [6 6]

[1 1][2    2] = [0 0]
[1 1][-2  -2]   [0 0]

</PRE>From these examples we see that the product is not commutative and that 
there are zero divisors. 
<H3><A name=Properties-of-multip><FONT color=#cc6600>Properties of 
multiplication of matrices</FONT></A></H3>
<H4><A name=Associativity><FONT color=#008c05>Associativity</FONT></A></H4>If 
the multiplication is defined then A(B.C) = (A.B)C holds for all matrices A,B 
and C.<BR>Proof: <BR>We'll show that an element of A(B.C) is equal to the 
corresponding element of (A.B)C<BR>First we calculate the element of the ith row 
and jth column of A(B.C) <PRE> 
Let D denote B.C, then
        d<SUB>k,j</SUB> = sum<SUB>p</SUB>  b<SUB>k,p</SUB>.c<SUB>p,j</SUB>        (1)

Let E denote A.D then
        e<SUB>i,j</SUB> = sum<SUB>k</SUB> a<SUB>i,k</SUB>.d<SUB>k,j</SUB> (2)

(1) in (2) gives
        e<SUB>i,j</SUB> = sum<SUB>k</SUB> a<SUB>i,k</SUB>.(sum<SUB>p</SUB> b<SUB>k,p</SUB>.c<SUB>p,j</SUB>)

&lt;=&gt;     e<SUB>i,j</SUB> = sum<SUB>k,p</SUB> a<SUB>i,k</SUB>.b<SUB>k,p</SUB>.c<SUB>p,j</SUB>

So the element of the ith row and jth column of A(B.C) is
        sum<SUB>k,p</SUB> a<SUB>i,k</SUB>.b<SUB>k,p</SUB>.c<SUB>p,j</SUB>               (3)
</PRE>Now we calculate the element of the ith row and jth column of (A.B)C <PRE> 
Let D' denote A.B, then
        d<SUB>i,p</SUB>' = sum<SUB>k</SUB> a<SUB>i,k</SUB>.b<SUB>k,p</SUB>        (4)

Let E' denote D'C then
        e<SUB>i,j</SUB>' = sum<SUB>p</SUB> d<SUB>i,p</SUB>'.c<SUB>p,j</SUB>       (5)

(4) in (5) gives
        e<SUB>i,j</SUB>' = sum<SUB>p</SUB> (sum<SUB>k</SUB> a<SUB>i,k</SUB>.b<SUB>k,p</SUB>).c<SUB>p,j</SUB>

&lt;=&gt;     e<SUB>i,j</SUB>' = sum<SUB>k,p</SUB> a<SUB>i,k</SUB>.b<SUB>k,p</SUB>.c<SUB>p,j</SUB>

So the element of the ith row and jth column of (A.B)C is
        sum<SUB>k,p</SUB> a<SUB>i,k</SUB>.b<SUB>k,p</SUB>.c<SUB>p,j</SUB>               (6)

From (3) and (6)  =&gt; A(B.C) = (A.B)C
</PRE>
<H4><A name=Distributivity><FONT color=#008c05>Distributivity</FONT></A></H4>If 
the multiplication is defined then A(B+C) = A.B+A.C and (A+B).C = A.C+B.C holds 
for all matrices A,B and C. This theorem can be proved in the same way as above. 

<H4><A name=Theorem-1><FONT color=#008c05>Theorem 1</FONT></A></H4>For each A, 
there is always an identity matrix E and an identity matrix E' so that A.E = A 
and E'.A = A If A is a square matrix, E = E'. 
<H4><A name=Theorem-2><FONT color=#008c05>Theorem 2</FONT></A></H4><PRE> 
        (A.B)<SUP>T</SUP> = B<SUP>T</SUP> .A<SUP>T</SUP>
</PRE>This theorem can be proved in the same way as above. 
<H4><A name=Theorem-3><FONT color=#008c05>Theorem 3</FONT></A></H4>If the 
multiplication is defined then for each A <PRE> 
        A.0 = 0 = 0.A
</PRE>
<H4><A name=Theorem-4><FONT color=#008c05>Theorem 4</FONT></A></H4>r and s are 
real numbers and A , B matrices. If the multiplication is defined then (rA)(sB) 
= (rs)(AB) This theorem can be proved in the same way as above. 
<H4><A name=Theorem-5><FONT color=#008c05>Theorem 5</FONT></A></H4><PRE> 
if D = diag(a,b,c) then D.D = ( a<SUP>2</SUP> , b<SUP>2</SUP> , c<SUP>2</SUP>)
                        D.D.D = ( a<SUP>3</SUP> , b<SUP>3</SUP> , c<SUP>3</SUP>)
                        .....
</PRE>This property can be generalised for D = diag(a,b,c,d,e,...,l). <BR><BR>
<HR>
<A href="http://www.ping.be/~ping1339/index.html#2"><B>Topics and 
Problems</B></A> <BR><BR><A 
href="http://www.ping.be/~ping1339/index.html"><B>MATH-abundance home page - 
tutorial </B></A><BR><BR><A 
href="http://www.ping.be/~ping1339/mathindex.htm"><B>MATH-tutorial Index 
</B></A><BR><BR>The tutorial address is http://home.planetinternet.be/~ping1339 
<BR><BR><A href="http://www.ping.be/~ping1339/copyright.htm">Copying 
Conditions</A> <BR><BR>Send all suggestions and remarks to Johan.Claeys@ping.be 
<BR><BR>
<HR>
</BODY></HTML>
